%%% This is an example file for the Auburn University style options
%%%       aums.sty (Masters Thesis)
%%%       auphd.sty (Ph.D. Dissertation)
%%%       auhonors.sty (Honors Scholar)

%%%To use it, please edit the necessary options, title, author, date, year, keywords, advisor, professor, etc. 

\documentclass[12pt]{report}
\usepackage{aums}       % For Master's papers
\usepackage{ulem}       % underlining on style-page; see \normalem below
\usepackage{url}
\usepackage{tikz}
\usepackage{pgf}
\usepackage{graphicx}
\usepackage{array}
%%%%%Format rules: Normal margins are 1 in. If you need to print with 1.5in margins, uncomment the line below
%\oddsidemargin0.5in \textwidth6in

%% If you do not need a List of Abbreviations, then comment out the lines below and the \printnomenclature line.
%%for List of Abbreviations information:  (see http://www.mackichan.com/TECHTALK/509.htm  )
\usepackage[intoc]{nomencl}
\renewcommand{\nomname}{List of Abbreviations}   	       
\makenomenclature 
%% don't forget to run:   makeindex ausample.nlo -s nomencl.ist -o ausample.nls

% This is so I can highlight things to get my attention when todoinepackage{color}
\usepackage{soul}
\newcommand{\todo}[1]{\hl{TODO: #1}}

% May want theorems numbered by chapter
\newtheorem{theorem}{Theorem}[chapter]

% Put the title, author, and date in. 
\title{Evaluating the Digital Fault Coverage for a Mixed-Signal Built-In Self Test}
\author{Michael Alexander Lusco} 
\date{May 10, 2011} %date of graduation
\copyrightyear{2011} %copyright year

\keywords{Built-In Self Test, Mixed-Signal, Testing}

% Put the Thesis Adviser here. 
\adviser{Charles Stroud}


% Put the committee here (including the adviser), one \professor for each. 
% The advisor must be first, and the dean of the graduate school must be last.
\professor{Charles Stroud, Chair, Professor of Electrical and Computer Engineering}

\professor{Foster Dai, Co-Chair, Professor of Electrical and Computer Engineering}

\professor{Vashani Agrawal, Professor of Electrical and Computer Engineering}

\professor{Victor Nelson, Professor of Electrical and Computer Engineering}

\begin{document}

\begin{romanpages}      % roman-numbered pages 

\TitlePage 

\begin{abstract}
This thesis focuses on a digital Built-in Self-Test (BIST)\nomenclature{BIST}{Built-in Self-Test} approach to perform specification-oriented testing of the analog portion of a mixed-signal system.  The BIST utilizes a Direct Digital Synthesizer (DDS)\nomenclature{DDS}{Direct Digital Synthesizer} based test pattern generator (TPG)\nomenclature{TPG}{Test Pattern Generator} and a multiplier-accumulator (MAC)\nomenclature{MAC}{Multiplier-Accumulator} based output response analyzer (ORA)\nomenclature{ORA}{Output Response Analyzer} to stimulate and analyze the analog devices under test.  This approach uses the digital-to-analog converter (DAC)\nomenclature{DAC}{Digital-to-Analog Converter} and the analog-to-digital converter (ADC)\nomenclature{ADC}{Analog-to-Digital Converter}, which typically already exist in a mixed signal circuits, to connect the digital BIST circuitry to the analog device(s) under test (DUT)\nomenclature{DUT}{Device Under Test}.

Previous work has improved and analyzed the capabilities and effectiveness of using this BIST approach to test analog circuitry; however, little work has been done to determine the fault coverage of the digital BIST circuitry iteself.  Traditionally additional test circuitry such as scan chains would be added to the BIST circuitry to provide adequate fault coverage of digital circuitry.  While ensuring that the digital circuitry is thoroughly tested and functioning properly, this scan chain circuitry incures a potentially high area overhead and performance penalty.  This thesis focuses on using the existing BIST circuitry to test itself by utilizing a dedicated digital loopback path.  A set of test procedures is developed and analyzed which can be used to provide a set of functional tests which provide a high effective fault coverage of the digital portion of the BIST.  To determine the effectiveness of these test procedures, the mixed-signal BIST circuit is simulated and single stuck-at gate-level fault coverage results are determined and presented.  Finally several improvements to the dedicated loopback path are proposed and simulated to analyze possible ways to improve the fault coverage of the BIST with minimal area and performance impact.
\end{abstract}

\begin{acknowledgments}
Put text of the acknowledgments here.
\end{acknowledgments}

\tableofcontents
\listoffigures
\listoftables

\printnomenclature[0.5in] %used for the List of Abbreviations
\end{romanpages}        % All done with roman-numbered pages


\normalem       % Make italics the default for \em


\chapter{Introduction}  % Use \\ for long titles 

The testing of embedded systems is a large field with many different approaches and techniques.  Some techniques work most effectively for digital systems and others for analog systems.  One approach is a hybrid test and is used to test a mixed-signal system -- a system with both digital and analog circuitry.  Mixed systems typically require the use of multiple testing techniques from both the digital and analog domains to be fully tested.  In this chapter a short introduction to testing and relevant testing techniques for digital, analog, and mixed-signal systems is given so that the reader can develop a foundation for understanding the mixed-signal testing approach studied in this thesis. 

\section{Why Test Circuits}
\label{sct:whytest}
According to Stroud\cite{stroud} there are three phases of a product where testing is of critical importance: the design phase, manufacturing phase, and the system operation phase.  Each phase of the product's life cycle uses testing to achieve different goals.  During the design phase of the product life cycle, the goal is to focus on finding and eliminating design errors.  During manufacturing the goal changes and is focused on eliminating manufacturer defects, and finally the operation phase is focused on ensuring fault-free operation.  All of these different testing goals work to improve the device by reducing costs, improving relability, etc.  

\section{The Basics of Testing}
\label{sct:basictesting}

The basics of testing a circuit are similar during all phases of a product's life-cycle:
\begin{itemize}
\item Generate a set of input stimuli or test vectors
\item Apply those vectors to the DUT
\item Compare the output of the DUT to the expected output for each input value
\item Note any discrepancies as indication that there is an error in the device (a fault)
\end{itemize}
In reality it is often more difficult to test circuits than this basic process makes it appear.  One way to ease this difficulty is by using design for testability (DFT)\nomenclature{DFT}{Design For Testability} techniques to increase the observability and controllability of a device during the design process\cite{stroud}.  Stroud defines observability and controllability in \cite{stroud} as the following:
\begin{quote}
``Controllability is the ease with which we can control a fault site and observability is the ease with which we can observe a fault site.\cite{stroud}''
\end{quote}
Ultimately these properties determine the complexity of testing a circuit.  As chips grow it becomes increasingly challenging to maintain an acceptable level of controllability and observability.  According to \cite{zorian}: 
\begin{quote}
``The growth rate in integrated circuit (IC)\nomenclature{IC}{Integrated Circuit} transistor count is far higher than the rate for IC pins and steadily reduces the accessibility of transistors from chip pins -- a big problem for IC test.\cite{zorian}''
\end{quote}
Large, modern circuits can contain billions of transistors and comparatively few IO pins\cite{zorian}.  Without careful design considerations these properties can negatively affect the testability of a device\cite{stroud}.

There are many different methods to physically testing a device.  Each method varies in its requirements and has its own unique set of challenges, costs, and advantages.  One traditional method of testing uses automatic testing equipment.  Automatic test equipment is commonly used during manufacturing to verify chips are manufactured without defects\cite{zorian}.  Unfortunately as the complexity and speed of IC's has increased, automatic testing equipment has struggled to maintain an acceptable test coverage of performance-related defects\cite{zorian}.  To test these more complex circuits requires more advanced and higher speed automatic test equipment with additional IO capabilities\cite{zorian}.  \cite{zorian} examines the cost of high-end automatic test equipment and finds they may become cost prohibitive for complex circuits.  \cite{itrs} estimates that without the inclusion of alternative testing approaches ``tester costs will reach up to \$20 million dollars in 2010''. One such alternative to more expensive testing equipment is Built-In Self-Test (BIST)\nomenclature{BIST}{Built-In Self-Test}. BIST describes the technique of designing a device to test itself\cite{stroud} and can complement or eliminate the need for automatic test equipment\cite{zorian}.

\section{Built-In Self-Test}
\cite{stroud} defines BIST as a circuit which can test itself and determine whether it is ``good'' or ``faulty.''  In essence this entails designing the circuit to perform all of the steps in section \ref{sct:basictesting} on itself.  \cite{stroud} continues by outlining the basics of a BIST architecture.  This simple architecture consists of several major components including a Test Pattern Generator (TPG)\nomenclature{TPG}{Test Pattern Generator} which generates the input stimuli necessary to test the circuit and an Output Response Analyzer (ORA)\nomenclature{ORA}{Output Response Analyzer} which compares the output of the circuit to the expected output for a given input value.  Additionally there is circuitry which isolates the Device Under Test (DUT)\nomenclature{DUT}{Device Under Test} during testing as well as circuitry which controls the test during execution (Test Controller)\cite{stroud}.

BIST has many advantages and disadvantages when compared to other techniques.  \cite{stroud} quantifies these advantages and disadvantages in Table \ref{tbl:advantages}. 
\begin{table}
	\caption{Advantages and Disadvantages of BIST\cite{stroud}}
	\begin{center}
	\begin{tabular}{|l|l|}
		\hline
		\multicolumn{1}{|c|}{{\bf Advantages}} & \multicolumn{1}{|c|}{{\bf Disadvantages}} \\ \hline
		Vertical testability (wafter to system) & Area overhead \\ \hline
		High Diagnostic resolution & Performance penalties \\ \hline
		At-speed testing & Additional design time \& effort \\ \hline
		Reduced need for automatic test equipment & Additional risk to project \\ \hline
		Reduced test development time \& effort & \\ \hline
		More economical burn-in testing & \\ \hline
		Reduced manufacturing test time \& cost & \\ \hline
		Reduced time-to-market & \\ \hline
	\end{tabular}
	\end{center}
	\label{tbl:advantages}
\end{table}
In addition \cite{ungar} performs a detailed economic analysis of including BIST in circuitry. \cite{ungar} concludes that:
\begin{quote}
``As the product develops from the IC to system level and its complexity increases, so does the complexity of successfully identifying a failure's root cause.  So it makes economic sense for system owners and perhaps system producers to implement BIST.\cite{ungar}''
\end{quote}
The advantages of BIST and its ability to reduce test time and cost make it an excellent choice for testing devices\cite{zorian}.

\subsection{Digital Systems and Faults}
\label{sct:digitalsystems}
Faults in a system are characterized by a fault model.  A common model used for digital systems (systems functioning at discrete `1' and `0' logic values) is the gate-level stuck-at fault model\cite{stroud}.  According to \cite{stroud}, the stuck-at fault model allows for faults at the input or output of a digital logic gate.  These faults can cause the input or output to be stuck-at a logic value `0' or `1' regardless of which value is applied or expected.  

Figure \ref{fig:andtruth} provides a truth table listing the faulty and fault-free output of an AND gate with its `A' input stuck-at `1'.  The `X' notation is used to indicate the location of the fault and the `SA1' (or `SA0') designates rather the fault is a stuck-at `1' or stuck-at '0'\cite{stroud}.  The truth table given in Figure \ref{fig:andtruth} shows how a single fault can change the behavior of a gate often having a major impact on the overall behavior of the circuit.
\begin{figure}[b!]
	\begin{center}
	\begin{minipage}[l]{.45\textwidth}
		\includegraphics[scale=.7]{images/and-gate}
	\end{minipage}
	\begin{minipage}[r]{.45\textwidth}
		\begin{tabular}{|c|c|c|}
			\hline
			Inputs & Fault Free & Faulty \\
			(AB) & Output (Z) & Output (Z) \\ \hline
			0 0 & 0 & 0 \\ \hline
			0 1 & 0 & 1 \\ \hline
			1 0 & 0 & 0 \\ \hline
			1 1 & 1 & 1 \\ \hline
		\end{tabular}
	\end{minipage}
	\end{center}
	\caption{AND Gate with Input A Stuck-At `1'}
	\label{fig:andtruth}
\end{figure}
Since digital circuits will always produce the same outputs for a given set of inputs, any difference between the expected and actual output can be exploited to determine if a circuit is functioning correctly\cite{stroud}.  Each clock cycle an input vector is applied and the output is compared with the expected output.  If any output does not match the expected output then the chip is considered faulty and is discarded.  Unfortunately the storage required to hold each input and expected output vector can be significant for large or complex chips and while feasible for costly automatic test equipment, it is often impossible due to area considerations when using a BIST approach\cite{faultdiagnosis}.

When using BIST the input vectors are often generated by the TPG circuitry deterministically, algorithmically, or pseudo-randomly (among other methods)\cite{stroud}.  This keeps the size of the TPG to a minimum and removes the need for a large memory or other means of storing every input vector.  Likewise it is impractical to store every expected output pattern and compare it to the actual output each clock cycle.  To minimize storage requirements a signature is often used to compress the output of the circuit into a single vector.  Instead of comparing each output at the end of each clock cycle, the signature is generated during the test and compared to the expected signature at the end of a test\cite{stroud}\cite{faultdiagnosis}.  A signature can be generated in a number of different ways and may be as simple as a counter counting the number of 1's or 0's which occur in the output, 1's or 0's counting, or as complex as using a large Multiple Input Signature Register\nomenclature{MISR}{Multiple Input Signature Register}\cite{stroud}.  The most appropriate signature generation method is dependent on the requirements and output of the design and can significantly impact the effectiveness of a BIST approach.  If a method is used which does not produce a suitably unique signature then faulty circuits can escape detection\cite{stroud}\cite{faultdiagnosis}.  The use of an expected signature to compress the circuit output allows for a significant reduction in storage cost as in most cases only a single comparison needs to be performed to verify the circuit\cite{faultdiagnosis}.

Returning to the example in Figure \ref{fig:andtruth}, a simple BIST can be constructed to test the AND gate.  In Figure \ref{fig:andbist} a 2-bit counter is used as the TPG to generate all of the inputs patterns possible for a two input AND gate: ``00'', ``01'', ``10'', and ``11''.  Also in the figure the output of the AND gate is connected to the \textit{Enable} of an additional 2-bit counter to count each `1' and produce a signature.  The fault-free signature for this circuit is ``01'' since a normally operating AND gate should only produce a single logic `1' when both its inputs are logic `1'.  If any input is stuck-at `1' then it will produce at least one additional `1'; if any input is stuck-at `0' it will never produce a logic `1'.  These two conditions will produce invalid signatures.  During execution of the BIST sequence, the TPG counts from ``00'' to ``11'' and the 1's counter will increment for each `1' occurring at the output of the gate.  At the end of the sequence, if the value in the 1's counter is not ``01'' then the gate is faulty.  This example is greatly simplified and is missing required circuitry to start and stop the BIST as well as a method to isolate the inputs of the gate; however, it does demonstrate the general principal behind using BIST to test a digital circuit.

\begin{figure}
	\begin{center}
		\includegraphics[scale=1]{images/and-bist}
	\end{center}
	\caption{Simple BIST for an AND Gate}
	\label{fig:andbist}
\end{figure}

\subsection{Analog Systems and Faults}
\label{sct:AnalogFaults}

Analog systems function differently than digital systems.  Unlike a digital system which only has two discrete values, analog systems are continuous waveforms with multiple levels and voltages\cite{syschip}.  In addition to the complexities of analog waveforms, analog components operate within a range of acceptable values\cite{syschip}.  This difference makes testing analog components for defects (defect-oriented testing) significantly more challenging and requires a more complex fault model.  In analog components faults are classified as either parametric (soft-faults) or catastrophic (hard-faults)\cite{analogfaults}.  Parametric faults are those which affect the performance of a specific component causing it to operate outside of its expected tolerance range, for example a resistor which has a lower than expected resistance.  In contrast catastrophic faults are those which cause a component to fail, such as resistor which is no longer conductive and appears as an open circuit\cite{analogfaults}.  The simulation of these different faults requires complicated and time consuming methods such as Monte Carlo analysis to determine different component values which allow fault-free circuit operation\cite{syschip}.  Compounding these issues is the fact that analog components
\begin{quote}
``function collectively to perform the overall functionality of a given circuit and, as a result cannot always be treated as a collection of individual components\cite{syschip}.''
\end{quote}
and consequently are difficult to isolate for effective defect-oriented testing\cite{analogmixedtest}.  Furthermore any circuitry added into an analog circuit may potentially interfere and change the operating range or output of that circuit\cite{syschip}.  This potential interference requires that any analog testing circuitry be carefully simulated and verified to ensure it does not negatively affect the overall circuit performance.  An example of a defected-oriented approach, oscillation testing is a testing approach which reconfigures the analog CUT so that it oscillates; this oscillation frequency is then measured and compared to an expected frequency.  If the measured frequency falls outside the expected range, the circuit is considered faulty\cite{analogosc}.  This method has been shown to be effective for the detection of catastrophic faults and some parametric faults; however, it can require a significant amount of planning and design effort as it may significantly impact the analog circuitry\cite{analogosc}\cite{syschip}.

A simpler (and preferred\cite{syschip}) method for testing analog components is via functional testing. \cite{milor} defines functional tests as: 
\begin{quote}
``... those which measure a circuit's dynamic behavior ...\cite{milor}''
\end{quote}
Functional or specification testing is achieved by performing a set of tests to determine if a system is operating correctly as defined by its specifications.  This approach is used to test the entire analog system collectively instead of attempting to understand the implications of specific faulty components\cite{analogmixedtest}.  Specification testing may include the testing of important analog characteristics such as frequency response, linearity, and signal-to-noise ratio (SNR)\nomenclature{SNR}{Signal-to-Noise Ratio}\cite{syschip}; however, the characteristics which are important  to test will vary between designs.  To adequately test most analog components, multiple measurements of several different characteristics must be taken as a single characteristic is usually not sufficient to ensure fault-free operation\cite{analogmixedtest}.  This process may require extra development time as test procedures must be developed to test each characteristic and additional time is required to perform each test\cite{analogmixedtest}.

\subsection{Mixed Signal Testing}
\label{sct:MixedSignal}
In a mixed-signal environment both digital and analog systems coexist and interact.  Due to the previously discussed differences in testing analog and digital systems, the testing of the analog and digital sub-systems is generally developed separately and performed using using different test procedures and approaches\cite{analogmixedtest}.  Ideally a designer would like to limit any duplicate work and take advantage of a BIST approach which can be used to test both the analog and digital sub-systems.

\cite{stroud} defines a BIST approach to testing mixed-signal systems shown in Figure \ref{fig:mixedbist1}.  This BIST uses a digital BIST approach to functionally test the analog sub-system by measuring certain analog characteristics which can be used ensure that the circuit is operating within its specifications.  This architecture is largely digital and thus can be integrated into the digital circuitry already in the system with minimal analog overhead.  This prevents excessive interference with the analog circuitry, excluding analog multiplexers which facilitate the sending and retrieving of test values to and from the analog sub-system\cite{stroud}.  To test the analog circuitry, the BIST uses the existing Digital to Analog Converter (DAC)\nomenclature{DAC}{Digital to Analog Converter} to convert digitally generated test patterns from the TPG to analog signals and the existing Analog to Digital Converter (ADC)\nomenclature{ADC}{Analog to Digital Converter} to convert the analog response back into the digital domain for analysis by the ORA\cite{stroud}.
\begin{figure}
	\begin{center}
		\includegraphics[scale=1]{images/mixed-bist-architecture}
	\end{center}
	\caption{BIST Approach for Mixed-Signal Systems\cite{stroud}}
	\label{fig:mixedbist1}
\end{figure}

Figure \ref{fig:mixedbist1} shows a basic version of this mixed-signal BIST approach using two multiplexers.  In this case one multiplexer is placed before the DAC to select between the BIST patterns and the system circuitry and a second multiplexer is positioned at the input of the analog system to select between the system level inputs and the analog outputs.  These two multiplexers form a loop allowing the generated TPG pattern to be converted into an analog signal and propagate through any analog circuitry before being routed back through the analog inputs to the DAC for analysis by the ORA.  While this implementation does allow testing of all analog components, it does not allow a high level of diagnostic resolution\cite{syschip}.  To obtain a higher diagnostic resolution, additional analog multiplexers can be added to further partition the system. Figure \ref{fig:mixedbist_paths} shows an example of an implementation with three separate multiplexed or loopback paths to facilitate a higher level of diagnostic resolution.  In Figure \ref{fig:mixedbist_paths} the shortest loop, the short dashed path, is a digital only path (digital loopback path) which can be used to test that the digital BIST is fault-free.  The next loopback path, the dashed path, connects the output of the DAC to the ADC bypassing any of the analog circuitry (from here on referred to as the bypass path).  This allows the verification of the ADC and DAC separately from the analog circuit.  The final path is the analog test path, the dotted path, and is similar to the path in Figure \ref{fig:mixedbist1} in that it is responsible for testing the analog circuitry.  There is no limit to the number of multiplexers that can be added to the system other than the increase in area overhead\cite{syschip}.  Additional analog multiplexers could be added to the example in Figure \ref{fig:mixedbist_paths} to further partition the analog circuitry and resolve faulty behavior to a specific portion of the analog DUT.
\begin{figure}
	\begin{center}
		\includegraphics[scale=1]{images/mixedbist-paths}
	\end{center}
	\caption{Mixed-Signal BIST with Multiple Loopback Paths}
	\label{fig:mixedbist_paths}
\end{figure}

In Figure \ref{fig:mixedbist_paths} the digital loopback path is of particular importance.  \cite{stroud-analog} has shown that a digital loopback path is highly advantageous when testing the digital portion of the BIST circuitry.  In a digital only environment the BIST produces exactly one output for a given set of inputs; however, without the digital loopback path the TPG outputs are not directly observable.  To observe the outputs of the TPG requires conversion via the DAC and reconversion via the ADC.  This will cause variations in the expected results due to the inherent variations which occur in analog signals and circuits.   To account for these variations, a range of acceptable values must be considered instead of an exact signature\cite{stroud-analog}.  

Figure \ref{fig:analog-faultcvg}
\begin{figure}
	\begin{center}
		\includegraphics[scale=.7]{images/analog-fault-coverage}
	\end{center}
	\caption{Fault Coverage v. Acceptable Value Range\cite{stroud-analog}}
	\label{fig:analog-faultcvg}
\end{figure}
shows a comparison of the maximum achievable digital fault coverage versus the allowed distance away from the expected good signature for different ORA designs.  In the figure, three different 8-bit ORA accumulator designs are considered  (ORA design is discussed in more detail in the next chapter).   Figure \ref{fig:analog-faultcvg} shows that regardless of design a (in some cases significant) reduction in the maximum achievable fault coverage is to be expected when a range of good values is considered instead of an exact signature.  Thus the only way to achieve the maximum fault coverage is to not use a range of acceptable values and perform a digital only test.  This requires the digital loopback path\cite{stroud-analog}.  Performing a digital only test separates the digital and analog systems when testing.  This allows for the usage of tools and techniques which target digital components separately from those used to generate the analog functional tests on the analog sub-system\cite{stroud-analog}.  When the three loopback paths shown in Figure \ref{fig:mixedbist_paths} are present, the test procedure should be performed first over the digital loopback path to verify the digital BIST, then using the bypass path to verify that the ADC and DAC path are functioning correctly, and finally over the entire circuit to verify the analog DUT\cite{syschip}\cite{stroud-analog}.

Though this technique still requires the separate testing of the analog and digital circuitry, it is an improvement over the previously discussed method since the same BIST circuitry can be used to test both the digital and analog circuitry\cite{stroud}.  This limits the amount of work that must be duplicated to the determination of which tests must be run and the expected values or range of values that must be considered.  Furthermore the basic procedure for testing the analog and digital circuits is the same (the only differences being which loopback path is selected and the actual test being performed) which will limit the differences between test sessions.

\section{Summary}
In the previous chapter a high-level look at both digital and analog systems has been given as well as the challenges of testing these systems for faults.  The concept of BIST has been presented along with its advantages and a simple BIST architecture.  In addition the challenges of testing mixed-signal systems has been discussed and a basic mixed-signal BIST model has been given along with an overview of the challenges of testing the BIST without a digital loopback path.  In the next chapter a more detailed explanation of fault simulation and of the specific mixed-signal BIST approach studied in this thesis is given.  This approach builds upon the simple architecture discussed in the previous section and addresses the challenges discussed in Section \ref{sct:AnalogFaults}.  Building upon this explanation, Chapter III explores the preparation necessary for simulating the mixed-signal BIST including necessary conversions and verification.  Chapter IV explores the main topic of this thesis: testing the actual mixed-signal testing circuitry to determine the level of fault coverage achievable.  Methods for improving the BIST and the maximum achievable fault coverage are explored in Chapter V, before a summary and conclusions are given in Chapter VI.

\chapter{Background}
Before discussing the fault simulations performed in this thesis, it is important to have a more thorough understanding of fault simulation techniques.  In this chapter, an overview of several fault simulation techniques will be given as well as an overview of the bridging fault model which models faults between nets.  Following this discussion a more detailed outline of the simulation and design process will be given.  Next the fault simulator AUSIM\nomenclature{AUSIM}{Auburn University SIMulator} is detailed which is used to evaluate the fault coverage of the mixed-signal BIST approach studied in the rest of this thesis.  This chapter concludes with a detailed discussion of the architecture of the mixed-signal BIST and its capabilities.

\section{Fault Simulations}
\label{sct:faultsim}
% An introduction to fault simulation is probably appropriate
Knowledge of the basic concepts of simulation is important to understanding how fault simulations are performed.  The simulation process begins with a netlist.  The netlist represents the circuit design to be simulated and defines the structure of the circuit at the gate level.  This includes both the gates used by the circuit as well as the interconnections between those gates\cite{advancedverilog}.  The generation of a netlist is discussed in more detail in Section \ref{sct:designprocess}.  According to Section \ref{sct:basictesting}, the next step is to generate a set of test vectors to be used to stimulate the circuit during testing.  Test vectors may be generated automatically using an Automatic Test Pattern Generator (ATPG)\nomenclature{ATPG}{Automatic Test Pattern Generator}\cite{advancedverilog} or manually by the designer.  When performing fault simulations, these vectors should ideally exercise as much of the internal circuitry of the design as possible so that a high fault coverage can be achieved (fault coverage is discussed towards the end of this section); consequently, test vectors generated using an ATPG can be advantageous as they typically guarantee a very high fault coverage\cite{advancedverilog}.  If vectors are created manually by the designer then it may be necessary to perform a logic simulation of the circuit to ensure the vectors are valid and to obtain the fault-free output of the circuit (when using an ATPG the fault-free output is generally recorded along with the test vector set).  With both the test vector set generated and fault-free output of the circuit known, fault simulations can begin.  

Fault simulation starts with the selection of a fault model which characterizes the fault behavior to be simulated.  There are several different fault models used for digital circuits, but the focus of this thesis will be the gate-level stuck-at fault model which was introduced in Section \ref{sct:digitalsystems}.  The stuck-at fault model has a low computation cost and accurately represents the behavior of faults seen at the gate-level of digital circuits\cite{stroud}.  Other models exist which characterize different fault behavior and have their own set of advantages and disadvantages.  The bridging fault model, which will be introduced in Section \ref{sct:bridgingfaults}, focuses on faults which occur between nets as opposed to those that occur at gate inputs and outputs and is used to accurately simulate faults that occur in circuit routing\cite{stroud-bridging}.  The transistor fault model targets faults which occur at the transistor level.  This level of detail makes it more computationally expensive to simulate compared to the gate-level model; however, this model more accurately represents the behavior of faults which occur during the manfacturing process\cite{defectforcmos} and may detect faults which are not detectable using the stuck-at fault  model.  Regardless of its accuracy, it is more common to use the gate-level stuck-at model for digital fault simulations since it is less computationally expensive and is acceptably accurate at modeling the behavior of common defects in digital systems\cite{defectforcmos}.  

Once a fault model is chosen each fault must be simulated and the output of the circuit recorded.  The output of the faulty circuit is compared to the fault-free output and if any discrepancy is found then the fault is recorded as detected.  Similarly if the output of the circuit is always the same as the fault-free circuit then the fault is not detected\cite{defectforcmos}.  In some cases a fault may be considered potentially detected; this special case is caused by an unknown logic value occurring in the circuit and is an artifact of simulation.  An unknown logic value will occur if a circuit element is not initialized properly\cite{stroud}.  In physical hardware the value must be either logic `0' or logic `1'; however, in simulation it is unknown which logic value it will initialize to which causes the detection of the fault to be uncertain in simulation\cite{stroud}.  The percentage of faults detected is said to be the fault coverage of the test vector set\cite{defectforcmos}\cite{stroud}.  Fault coverage is typically calculated using Equation \ref{equ:faultcvg} where $D$ is the number of detected faults, $P$ is the number of potentially detected faults, $X$ is the number of undetectable faults and $T$ is the total number of faults simulated\cite{stroud}.  
\begin{equation}
F_C = \frac{(D + .5P)}{(T - X)}
\label{equ:faultcvg}
\end{equation}
Undetectable faults are faults which are impossible to detect by any test vector.  These faults are often caused by design issues such as re-convergent fan-out and redundant logic\cite{stroud} and since they cannot be detected are typically not considered when calculating fault coverage.  In the equation $P$ is multiplied by $.5$ denoting that there is a 50\% change of a potentially detected fault being detected.  This represents the chance of an uninitialized logic value initializing to the logic value required for detection when testing is performed in physical hardware.  This coefficient may be changed to represent a higher or lower chance of detecting potentially detectable faults\cite{stroud}.

For a large number of faults or large number of test vectors the simulation process can take a large amount of time to complete. In the worst case the time required to complete a fault simulation is shown in Equation \ref{equ:fsimtime}, where $T_{vec}$ is the time required to simulate a single vector, $N_{vec}$ is the number of test vectors to be simulated, and $N_{flts}$ is the number of faults to be simulated.  
\begin{equation}
Time = T_{vec} \times N_{vec} \times N_{flts}
\label{equ:fsimtime}
\end{equation}
There are a couple of methods which can decrease the amount of time taken to simulate a list of faults.  One common method is fault dropping.  When using fault dropping a fault is only simulated until a discrepancy between the output of the circuit and the fault-free output is found.  At that point the fault is recorded as detected, simulation of the fault is halted, and a new fault is simulated\cite{stroud}.  The time required to perform fault simulation when using fault dropping is shown in Equation \ref{equ:fdroptime} where $N_{flts}$ is the number of faults to be simulated, $T_{vec}$ is the time required to simulated a single vector, and $N_{vec_i}$ is the number of vectors simulated for the $i^{th}$ fault.
\begin{equation}
Time =  \sum_{i=0}^{N_{flts}} T_{vec} \times N_{vec_i}
\label{equ:fdroptime}
\end{equation}
In the case where the $i^{th}$ simulated fault is detected early in the simulation, $N_{vec_i}$ will be small shortening the simulation time for the fault; in contrast, if the $ith$ fault is detected toward the end of the simulation or not detected at all then $N_{vec_i}$ will be approximately $N_{vec}$ causing little to no savings in simulation time for the fault\cite{stroud}.  

Further speed up can be obtained by performing parallel fault simulation.  Equations \ref{equ:fsimtime} and \ref{equ:fdroptime} show the time required to perform serial fault simulations where a single fault is simulated at a time.  To decrease the time required for simulation, it is beneficial to simulate multiple faults concurrently\footnote{This does not mean perform the simulation of multiple faults in the same circuit simultaneously; but instead, it means perform multiple simulations in parallel each with a single fault\cite{parallelflts}}. This is a common approach to decreasing simulation time and at least in the case of gate-level stuck-at fault simulation, does not require any additional considerations by the user\cite{parallelflts}.  Commonly 32 faults\footnote{An integer is 32-bits on a 32-bit machine; consequently, simulating 32 faults allows for the use of the integer data type in the simulator and makes parallel fault simulation easier to implement\cite{parallelflts}} are simulated in parallel though different simulators may have options to simulate more or less faults\cite{parallelflts}.  Equation \ref{equ:psimtime} defines the worst case time required to perform parallel fault simulation and Equation \ref{equ:psimdroptime} defines the time required to perform parallel fault simulation with fault dropping assuming 32 faults are simulated in parallel (in this case $N_{vec}$ is the number of vectors required to detect all faults in a parallel group). 
\begin{equation}
Time = T_{vec} \times N_{vec} \times \frac{N_{flts}}{32}
\label{equ:psimtime}
\end{equation}
\begin{equation}
Time =  \sum_{i=0}^{\frac{N_{flts}}{32}} T_{vec} \times N_{vec_i}
\label{equ:psimdroptime}
\end{equation}
Using both fault dropping and parallel fault simulation can greatly decrease the required simulation time for a large circuit.  Due to this benefit both of these methods are used in the fault simulations performed in this thesis.  The next section discusses further optimizations which can be performed to reduce the number of faults simulated and consequently the time required to perform simulation.

\subsection{Collapsed vs Uncollapsed Faults}
% This should discuss collapsed vs uncollapsed as it relates to the stuck-at fault model
% An image showing some faults and the collapsed version (similar to Dr. Strouds image from BIST would be good)
% Can greatly improves simulation time, disadvantages? FC related I guess?
% give an example of the difference: use the BIST... why not
When performing fault simulations certain optimizations can be made to improve the efficiency of the simulation.  One such optimization is fault collapsing.  With the gate-level single stuck-at fault model, each gate input and output can be stuck-at logic `0' or logic `1'.  For elementary logic gates this leads to many faults which produce identical faulty behavior; these faults can be said to be equivalent\cite{defectforcmos}.  During simulation these equivalent faults can be collapsed, requiring only a single fault out of the group of equivalent faults to be simulated\cite{defectforcmos}.  Depending on the circuit this can substantially reduce the number of faults to be simulated while still accurately representing the faults which can occur in the circuit\cite{defectforcmos}.  Figure \ref{fig:faultcollapse} shows an example of fault collapsing.  The NOR gate in the figure has six uncollapsed faults; however, when either input is stuck-at `1' it is equivalent to the output being stuck-at `0' and vice versa (since a logic `1' is the controlling input for a NOR gate) which results in four collapsed faults.  These equivalent faults are shown in bold in the figure.
\begin{figure}
	\begin{center}
		\includegraphics[scale=1]{images/nor-faultcollapse}
	\end{center}
  \caption{NOR Gate with Six Uncollapsed and Four Collapsed Faults}
  \label{fig:faultcollapse}
\end{figure}
\cite{stroud} states that the number of collapsed faults for any elementary logic gate with greater than one input is $K+2$ where $K$ is the number of inputs to the gate.  This is certainly apparent with the NOR gate in Figure \ref{fig:faultcollapse}, where $K+2=4$.  Additionally when the output of a gate is connected to exactly one input of another gate, a fault occurring at the output of the source gate is indistinguishable from the same fault occurring at the input of the connected gate\cite{stroud}.  These faults can be structurally collapsed together which leads to a large chain of faults being collapsed such as the example in Figure \ref{fig:collapsechain}\cite{stroud}.  In the figure groups of equivalent faults are shown with a line drawn between them.  Unfortunately due to the limitation of the single stuck-at fault model, which does not allow multiple faults to appear in the circuit simultaneously (as opposed to a multiple fault model which allows this), the fan-out stem in Figure \ref{fig:collapsechain} cannot be collapsed\cite{defectforcmos}.  Since the output of the inverter fans-out to the input of two different gates, collapsing these faults would make a fault appear to be on both the input of the AND gate and the OR gate simultaneously which violates the single stuck-at fault model and is not allowed\cite{defectforcmos}.  Counting the faults in the figure, there are a total of 22 uncollapsed faults and a total of 12 collapsed faults, a significant reduction.
\begin{figure}
	\begin{center}
		\includegraphics[scale=1]{images/faultchain-collapse}
	\end{center}
  \caption{Structural Fault Collapsing Performed on a Group of Logic Gates}
  \label{fig:collapsechain}
\end{figure}

In the single stuck-at fault model the number of uncollapsed faults in a circuit are $2 \times G_i_o$ where $G_i_o$ is the number of gate inputs and outputs in the circuit\cite{stroud}.  In contrast the number of collapsed faults can be determined by Equation \ref{equ:collapse-eq} where $P_o$ is the number of primary outputs, $F_o$ is the number of fan-out stems, $G_i$ is the number of gate inputs, and $N_i$ is the number of inverters in the circuit\cite{stroud}.
\begin{equation}
F = 2(P_o + F_o) + G_i - N_i
\label{equ:collapse-eq}
\end{equation}
As an example, the BIST model evaluated in this thesis has a total of 83386 uncollapsed faults.  It has 30 primary outputs, 4436 fan out stems, 27861 gate inputs, and 2740 inverters.  By using Equation \ref{equ:collapse-eq} the number of collapsed faults in the BIST circuitry is 34053.  This results in a 59\% reduction in the number of faults to be simulated.  

\cite{stroud} discusses the advantages and disadvantages of using the collapsed or uncollapsed fault set for simulation purposes.  According to \cite{stroud} it is obvious that the simulation time can be greatly reduced by using the collapsed fault list.  This is very advantageous as more simulations can be performed in the same amount of time.  However, \cite{stroud} does say that the uncollapsed fault list more accurately represents the possible defects which occur during manufacturing.  Due to this difference, the fault coverage obtained with the collapsed fault list will be different than the coverage according to the uncollapsed fault list by a few percent\cite{stroud}.  Through the accuracy of the uncollapsed fault list is preferable, the collapsed fault list is more often used due to its decreased simulation time\cite{stroud}.


\subsection{The Bridging Fault Model}
\label{sct:bridgingfaults}
% Discuss multiple models
% Discuss in detailed dominant model
% Discuss collapsed vs uncollapsed
% Can be difficult to simulate due to large number of faults sites (N^2-N)/2
Though the focus of this thesis is gate-level stuck-at fault simulations, additional models may be of interest for future work; specifically bridging fault simulations are commonly performed to assess the fault coverage of faults which occur between nets.  There are a number of different fault models which describe the behavior of bridging faults, faults where two nets are shorted together due to a manufacturing defect, including the Wired OR/AND, Dominant, and Dominant OR/AND fault model\cite{stroud-bridging}.  In this section we will focus on the dominant bridging fault model as it is the most commonly used\cite{stroud}.  For many years it was a commonly held belief that a high stuck-at fault coverage provided a high bridging fault coverage; however, more recent work has shown that this is not always the case and that it is important to perform these simulations separately to ensure that an acceptably high bridging fault coverage is achieved\cite{stroud-bridging-physical}.  Unfortunately bridging fault simulation can be significantly more time consuming than stuck-at fault coverage due to the large number of fault sites that must be considered.
\begin{equation}
F_B = (N^2-N)/2
\label{equ:bridging-fault-sites}
\end{equation}
Equation \ref{equ:bridging-fault-sites} shows the calculation to determine the number of possible bridging fault sites in a circuit, where $N$ is the number of nets in the circuit\cite{stroud}.  Like the previous section, the BIST model can be used to give a sense of scale.  The BIST studied in this thesis has 15221 nets, by applying Equation \ref{equ:bridging-fault-sites} the number of bridging fault sites is 115,831,810!  Depending on the bridging fault model up to four faults (when using the DOM AND/OR model\cite{stroud-bridging}) are possible at each fault site, so this means that the worst case number of faults to be simulated is almost 500 million!  Similar to the gate-level model, bridging faults can also be structurally collapsed which can substantially lower the number of faults to be simulated (using the same circuit the number of collapsed faults was approximately 30K when using the more common dominant model).

As discussed in the previous paragraph, there are different models to define the types of bridging faults which can occur.  Since it is the most common, the dominant bridging fault model will be discussed.  According to the dominant bridging fault model, two different faults can occur at a bridging fault site: net A can dominate net B or net B can dominate net A.  Whichever net is dominated will be affected by the other net's current logic value; this occurs due to the dominate net having a stronger drive transistor\cite{stroud-bridging}.  Figure \ref{fig:bridgingfault} shows an example of a dominant bridging fault where net A dominates net B, along with a truth table containing the fault-free and faulty behavior of the circuit.  
\begin{figure}
  \begin{center}
    \begin{minipage}[l]{.55\textwidth}
      \begin{center}
        \includegraphics[scale=.8]{images/bridgingfault}	
      \end{center}
    \end{minipage}
    \begin{minipage}[r]{.35\textwidth}
      \begin{center}
        \begin{tabular}{|l|l|l|}
          \hline
          Net A & Net B & Faulty' \\ 
          & & Net B' \\ \hline
          0 & 0 & 0 \\ \hline
          0 & 1 & 0 \\ \hline
          1 & 0 & 1 \\ \hline
          1 & 1 & 1 \\ \hline
        \end{tabular}
      \end{center}
    \end{minipage}
  \end{center}
  \begin{center}
		\begin{minipage}[l]{.55\textwidth}
      \begin{center}
        (A)
      \end{center}
		\end{minipage}
		\begin{minipage}[r]{.35\textwidth}
      \begin{center}
        (B)
      \end{center}
		\end{minipage}
	\end{center}
  \caption{Bridging Fault where Net A Dominates Net B}
  \label{fig:bridgingfault}
\end{figure}
When net B has the same logic value as net A its output is unaffected; however, when the logic value of net B is different than that of net A, net B's logic value will be changed to that of net A.  The first two columns of the truth table in Figure \ref{fig:bridgingfault} represent the fault-free behavior of net A and net B and the remaining column B' represents the faulty output of net B when net A dominates it.  In the second row when net A is a `0' and net B should be a `1', B' is instead a `0' since it is dominated by net A.  Likewise in the third row when net A is a `1', net B should be a `0' but instead is a `1' due to the influence from net A.

Bridging faults are important to address during the design of a circuit.  Unfortunately they can be computationally expensive and can be difficult to test and observe\cite{stroud-bridging}.  Bridging faults were not simulated in this thesis though it is a target of future work.

\subsection{Design Process}
\label{sct:designprocess}
% Discuss behavioral -> place and route -> post-layout
% Advantages of simulating post-layout
% Transition into discussion on converting post-layout netlist (A tool was written for this purpose and is discussed in Chapter 3)
The design of a digital circuit typically starts with a behavioral description of a circuit.  This is generally done in a high-level design language such as Verilog or VHSIC Hardware Design Language (VHDL)\nomenclature{VHSIC Hardware Design Language}{VHDL} and usually will not include any implementation details of the circuit\cite{advancedverilog}.  This code is then fed into a synthesis computer-aided design (CAD)\nomenclature{CAD}{Computer-Aided Design} tool which will interpret the behavioral description of the design, combine it with parameters such as the implementation technology, timing information, and/or area constraints, and ultimately produce a gate-level netlist of the design\cite{advancedverilog}.  Following this step a place-and-route tool takes each gate and its interconnections and decides where on the silicon chip (or in the FPGA or other programmable device) to place the gate so that any timing and area constraints can be achieved.  Once completed the design is said to be ``post-layout'' indicating it is ready for fabrication\cite{advancedverilog}.

Logic simulation is important during each step of this design process, so that the circuit behavior can be verified before fabrication\cite{advancedverilog}.  During the behavioral modeling phase, design verification is performed to ensure the description of the circuit is correct and that no design errors have been made.  Simulation is also performed after synthesis has taken place to verify that the circuit's behavior is still correct after it has been implemented at the gate-level and to investigate any potential timing problems with the circuit\cite{advancedverilog}.  Following post-synthesis simulation, post-layout simulation is also performed.  Post-layout represents the final version of the circuit to be fabricated.  Simulation can be performed using the circuit's final timing information and can incorporate many different performance characteristics.  Post-layout is the final opportunity to verify a circuit is functioning correctly before fabrication\cite{advancedverilog}.

In contrast to logic simulation, fault simulation is not typically performed at any of the high-level steps in the design process\cite{stroud}.  Ideally the post-layout netlist should be used for all fault simulations, since the layout can have a significant impact on the faults in a circuit\cite{defectforcmos}.  This is especially true of bridging fault simulations as routing is not finalized until the layout stage and thus cannot be accurately performed earlier in the design process\cite{defectforcmos}; however, other fault models may be simulated earlier in the design verification process\cite{stroud}.  In this thesis all fault simulations of the BIST are performed using the post-layout design.  As discussed in the next chapter, this does present a challenge since the post-layout design produced by the CAD tools is a Verilog netlist which is not a format used by the fault simulator.  As such a tool was written to convert a Verilog netlist to the ASL netlist format recognized by our simulator AUSIM (ASL and the fault simulator AUSIM will be discussed in Section \ref{sct:ausim}).

\subsection{Value Change Dump File}
% Discuss a VCD file since it relates to simulation
% Simplifies the storage and viewing of simulations results
% A single paragraph should do
The Value Change Dump or VCD\nomenclature{VCD}{Value Change Dump} format is defined in section 15 of the IEEE 1364-1995 standard for Verilog\cite{verilog}.  Originally created as a light-weight format to dump simulation results for post-processing\cite{verilog}, the VCD format is an industry standard format and is typically used to store logic simulation results in as small of a footprint as possible\cite{verilog}.  In addition as an IEEE standard it is supported in a number of free and commercial viewers which can easily visualize and navigate the underlying simulation data. 

The VCD format compresses simulation results into a smaller footprint by only storing the changes between vectors instead of every vector\cite{verilog}.  While this can make the output of the file less readable it makes it very easy to store large amounts of simulation data and for a viewer to parse and display the file.  An example of a VCD file is shown in Table \ref{tbl:half_adder_vcd}\footnote{It is important to note that while all IO in this example are a single bit, values in a VCD file can be any arbitrary width and in that case operate as a bit-vector}.  On the right in Table \ref{tbl:half_adder_vcd} is a text description explaining each section of the VCD file.
\begin{table}
	\begin{center}
    \caption{Example VCD File}
		\begin{tabular}{l|l}
			VCD File & Description \\ \hline
			\textbf{\$date} & The date section defines the day\\
			Tuesday, December 07, 2010 & which this file was created \\
			\textbf{\$end} & \\
			\textbf{\$version}
			Generated For ASL2VCD 1.0 & A comment detailing the  \\
			Alex Lusco & version of the application creating this file \\
			\textbf{\$end}	\\
			\textbf{\$comment}	\\
			VCD File & An additional comment section detailing \\
			\textbf{\$end} & information about the file \\
			\textbf{\$timescale} 10ns \textbf{\$end} & Defines the time scale used in this file \\
			\textbf{\$scope} module logic \textbf{\$end} & The simulation scope, particular to the simulation \\
			\textbf{\$var} wire 1 ! A \textbf{\$end} & This section aliases each input with a single ASCII \\
			\textbf{\$var} wire 1 " B \textbf{\$end} & character. For long IO names this shrinks them to a  \\
			\textbf{\$var} wire 1 \# S \textbf{\$end} & single character allowing for the ability to condense \\
			\textbf{\$var} wire 1 \$ C \textbf{\$end} & the dump for large simulations greatly \\
			\textbf{\$upscope} \$end & \\
			\textbf{\$enddefinitions} \$end & End of header \\
			\textbf{\$dumpvars} & Sets the initial value for each input \\
			0!	& Each IO must be set to an initial value here \\
			0"	& The !,",\#, \& \$ characters represent the\\
			0\# & nets aliased in the \$var section\\
			0\$ & \\
			\textbf{\$end} & \\
			\textbf{\#1} & The \#N construct denotes a time step to apply the \\
			1" & following value changes at, in this case at 10ns \\
			1\# & Only nets whose value changed will appear in the time step\\
			\textbf{\#2} & These changes occurred at 20ns \\ 
			1! & \\
			0" & \\
			\textbf{\#3} & These changes occurred at 30ns\\
			1" & \\
			0\# & \\
			1\$ & \\	
			\textbf{\#4} & The end of the simulation, no changes occurred \\		
		\end{tabular}
	\end{center}
	\label{tbl:half_adder_vcd}
\end{table} 
In addition to the file size reduction, the key benefit of conversion to the VCD format is the ability to visualize the output of a logic simulation in one of a number of commercial viewer applications.  For the example in Figure \ref{fig:half-adder-gtkwave} GTKWave was used to visualize the VCD file in Table \ref{tbl:half_adder_vcd}.  GTKWave is a free, open source VCD file viewer for Linux available on-line at \url{http://gtkwave.sourceforge.net}.  In GTKWave each IO is displayed as a waveform.  The displayed waveforms can be panned, zoomed and combined.  This functionality alone makes it much easier to verify the output of a complex logic simulation.  Conversion to the VCD file format and the GTKWave viewer are used in this thesis to simplify the verification of test vectors used in fault simulations.
\begin{figure}
	\begin{center}
		\includegraphics[scale=.4]{images/half-adder-vcd}
	\end{center}
	\caption{VCD File Visualized in the GTKWave Viewer}
	\label{fig:half-adder-gtkwave}
\end{figure}

\section{AUSIM Fault Simulator}
\label{sct:ausim}
% Some discussion on the general use of the simulation
% Capabilities
For the fault simulations performed in this thesis the Auburn University SIMulator or AUSIM\nomenclature{AUSIM}{Auburn University SIMulator} is used.  Developed by Dr. Charles Stroud\cite{ausim}\cite{asl}, AUSIM can perform both logic and fault simulations.  In addition it supports multiple fault models including the gate-level stuck-at and multiple bridging fault models\cite{ausim}.  It supports all of the previously discussed methods of improving simulation time including fault collapsing and parallel fault simulation of both bridging and stuck-at faults\cite{ausim}.  A detailed description of the operation and usage of AUSIM will not be given in this thesis; however, more information can be found in \cite{ausim}\cite{asl}; instead, the focus of this section is an overview of the Auburn Simulation Language or ASL\nomenclature{ASL}{Auburn Simulation Language} which is the netlist format used by AUSIM.

\subsection{ASL Netlist Format}
% Format used by AUSIM for simulations
% Discussion of the specifics
Before a circuit can be simulated by AUSIM it must be in a format that AUSIM can understand.  The Auburn Simulation Language (ASL)\nomenclature{ASL}{Auburn Simulation Language} is the circuit description used by AUSIM\cite{asl}.  ASL is used to provide a textual representation of a circuit at the gate-level to the simulator.  This gate-level net-list is used to describe each connection and gate used in a circuit design and allows the simulator to build a representation of the circuit under test.  ASL begins with a top-level circuit declaration.  This declaration defines the name of the circuit and uses the \textit{in} and \textit{out} keywords to define the inputs and outputs to the circuit\cite{asl}.  An example circuit is given in Figure \ref{fig:half_adder}.  Figure \ref{fig:half_adder} A is a half-adder which takes in two inputs and outputs a sum (S) and carry bit (C), the corresponding ASL description is given in Figure \ref{fig:half_adder} B.
\begin{figure}
	\begin{center}
		\begin{minipage}[l]{.45\textwidth}
			\includegraphics[scale=1]{images/half-adder}	
		\end{minipage}
		\begin{minipage}[r]{.45\textwidth}
			\begin{center}
				Half-Adder Circuit
			\end{center}
			\begin{enumerate}
				\setlength{\itemsep}{0cm}
				\item \# Half-Adder ;
				\item ckt: HF in: A B out: S C ;
				\item xor: X1 in: A B out: S ;
				\item and: A1 in: A B out: C ;
			\end{enumerate}
		\end{minipage}
	\end{center}
	\begin{center}
		\begin{minipage}[l]{.45\textwidth}
			(A)
		\end{minipage}
		\begin{minipage}[r]{.45\textwidth}
			(B)
		\end{minipage}
	\end{center}
	\caption{A Half-Adder Circuit}
	\label{fig:half_adder}
\end{figure}
As can be seen from the figure the circuit declaration is started by the \textit{ckt} keyword\cite{asl}.  Each keyword in ASL is followed by a `:' character\cite{asl}.  Following the \textit{ckt} keyword is the name of the circuit in this case ``HF''.  Following that, the primary inputs and outputs are declared using the \textit{in} and \textit{out} keywords.  Each statement in ASL is terminated using a `;' character\cite{asl}.  After the circuit statement the gate-level description of the circuit is given.  The format of each gate is similar to the format of the circuit statement:
\begin{quote}
	\textbf{GATE}: Name \textbf{IN}: In1 In2... InN \textbf{OUT}: Out1 Out2... OutN ;\cite{asl}
\end{quote}
All gate declarations in ASL follow this simple syntax.  All of the elementary logic gates (AND, OR, XOR, etc..) as well as the data flip-flop (DFF)\nomenclature{DFF}{Data Flip-Flop} and two input multiplexer are built-in to AUSIM and available to all circuits\cite{asl}.  Table \ref{tbl:ASLGates} shows each built-in gate and its inputs and outputs.
\begin{table}[bht]
\caption{Built-In AUSIM Gates\cite{asl}}
\begin{center}
\begin{tabular}{|l|l|}
\hline
\multicolumn{2}{|c|}{AUSIM Keywords} \\ \hline
Gate & Example \\ \hline
AND & AND: a1 in: i1.. iN out: Z \\ \hline
OR & OR: o1 in: i1.. iN out: Z \\ \hline
NAND & NAND: na1 in: i1.. iN out: Z \\ \hline
NOR & NOR: no1 in: i1.. iN out: Z \\ \hline
NOT & NOT: n1 in: A out: nA \\ \hline
XOR & XOR: x1: in: i1... iN out: Z \\ \hline
MUX2 & MUX2: m1 in: i1 i2 s1 out: Z \\ \hline
DFF & DFF: d1 in: CLK D out: Q \\ \hline
\end{tabular}
\end{center}
\label{tbl:ASLGates}
\end{table}

It is important to understand that custom gates can be implemented hierarchically and used in a similar syntax.  To do this one must use the \textit{subckt} command.  While an ASL file can only have a single circuit declaration, it can have any number of sub-circuit declarations\cite{asl}.  Each sub-circuit has its own set of top-level inputs and outputs and its own gate-level net-list.  Once defined the name of the sub-circuit can be used as a gate and be instantiated elsewhere in the circuit description.  These sub-circuit definitions can be used to define the behavior of more complex CMOS standard cell gates such as the OAI222 etc.  For the BIST discussed in this thesis, an entire library of sub-circuits was created to support simulation.  This library defines many of the complex CMOS logic gates and several technology specific standard cells.  This library is discussed in more detail in Chapter 3.

\section{BIST Architecture}
% Introduce the bist, its SSA BIST based on a DDS
% some other introductory characteristics
The BIST architecture tested in this thesis is a mixed-signal BIST approach which uses Selective Spectrum Analysis (SSA)\nomenclature{SSA}{Selective Spectrum Analysis} to functionally test analog circuitry.  SSA has many advantages when used to measure frequencies in an analog spectrum.  First it benefits from being a largely digital approach and integrates well into a BIST environment\cite{jie-journal}.  In addition due to SSA measuring only a single frequency point at a time, the hardware overhead is much lower when compared to alternative approaches such as FFT-BIST\cite{stroud-phase}. However, since only a single frequency is measured at one time, test time can become long when a large number of frequencies are of interest.  Likewise SSA can prove very advantageous when only a few frequencies are of interest in the analog spectrum\cite{jie-journal}.  In addition \cite{jie} discusses a number of optimizations in detail (some of which will be discussed in Section \ref{sct:bist-ora}) which when used can greatly reduce the time required to perform a measurement.

\begin{figure}
	\begin{center}
		\includegraphics[scale=.5]{images/bist-ssa-architecture}
	\end{center}
	\caption{General BIST Architecture\cite{testtime}}
	\label{fig:bist-ssa}
\end{figure}
A block diagram of the basic architecture of the studied BIST SSA approach can be seen in Figure \ref{fig:bist-ssa}.  This BIST architecture is capable of measuring a number of different analog characteristics including the frequency response and linearity (also known as third-order interception point or IP3\nomenclature{IP3}{Third Order Interception Point}) of a DUT\cite{basessa}.  In addition by sweeping through a frequency spectrum both Signal-to-Noise Ratio (SNR)\nomenclature{SNR}{Signal-to-Noise Ratio} and Noise Figure\cite{noisefigure} and be measured.  The architecture in Figure \ref{fig:bist-ssa} consists of a Direct Digital Synthesis (DDS)\nomenclature{DDS}{Direct Digital Synthesis} based TPG, Multiplier-Accumulator (MAC)\nomenclature{MAC}{Multiplier Accumulator} based ORA, and test controller (not shown).  Also not shown in the figure is the on-chip calculation circuit which will be discussed in detail in Section \ref{sct:onchip}.  The following sections will discuss each of the major BIST components and discuss how each test is performed and calculated so that the reader can developer a thorough understanding of the capabilities and uses of this BIST architecture.

\subsection{DDS Based TPG}
% Discuss DDS based frequency generation
% Discuss frequency words and how they relate to the clock speed and frequency generation
DDS is a popular technique for generating analog frequencies on chip.  Compared to other techniques of frequency generation it offers the ability to produce very precisely controlled frequencies which can be rapidly manipulated and changed using digital inputs.  In addition with adequate design considerations, DDS designs can have extremely fine frequency and phase resolution\cite{qi}.  The BIST TPG is DDS based consisting of three numerically controlled oscillators (NCOs)\nomenclature{NCO}{Numerically Controlled Oscillator} which utilize the existing DAC in the mixed-signal system to generate the analog waveforms for testing\cite{testtime}.  Each NCO utilizes a phase accumulator and sine/cosine lookup table (LUT)\nomenclature{LUT}{Lookup Table} to produce a frequency based on a supplied frequency word $f_w$. The supplied frequency word is accumulated each clock cycle by the phase accumulator.  The value of the phase accumulator is truncated and used as a lookup address to find the appropriate sine or cosine value in the LUT.  The value retrieved from the LUT is then converted by the DAC into an analog signal.  The basic steps of this process are shown in Figure \ref{fig:dds}.  
\begin{figure}
  \begin{center}
		\includegraphics[scale=.8]{images/dds-steps}
  \end{center}
  \caption{Block Diagram of DDS}
  \label{fig:dds}
\end{figure}
The resulting frequency generated by the NCO is determined by Equation \ref{eq:frequencyword}, where $f_{gen}$ is the generated frequency, $f_w$ is the supplied frequency word, $f_{clk}$ is the system clock frequency, and $n$ is the number of bits in the frequency word.  The maximum frequency resolution of the DDS is directly related to the number of bits used for the frequency words, $n$.
\begin{equation}
	f_{gen} = \frac{f_w \times f_{clk}}{2^{n}}
	\label{eq:frequencyword}
\end{equation}

As shown in Figure \ref{fig:bist-ssa}, there are three NCOs.  The first two NCOs are used to generated frequencies which stimulate the analog DUT.  There are two possible configurations for these two NCOs when testing the analog DUT.  In case one, only a single tone needs to be generated for testing.  This case is used when performing tests such as frequency response at a given frequency (tests will be explained in more detail in Section \ref{sct:onchip}\cite{jie-journal}).  When only a single tone is necessary, both NCOs are supplied the same frequency word and produce the same frequency\cite{jie}.  This frequency output is then selected and passed into the DUT.  In the second case, two different tones are generated such as when a linearity test is performed.  In this case $NCO_1$ is assigned the first frequency word and $NCO_2$ is assigned the second.  The output of these two NCOs is added together so that the two sine waves are super-imposed before being converted by the DAC\cite{jie}.  The third NCO $NCO_3$ is used by the ORA.  $NCO_3$ is slightly different than both $NCO_1$ and $NCO_2$ in that it produces both the sine and cosine output for a given frequency word.  These two outputs are used by the ORA to measure the in-phase and out-of-phase components of the DUT response at a frequency of interest (the ORA operation is explained in detail in the next section)\cite{jie}.   These three NCOs allow for up to two separate frequencies to be generated simulatenously as well as any frequency of interest to be measured by the ORA.  When coupled with the test controller, this architecture is very powerful and as will be discussed shortly can be used to measure several significant analog characteristics.

\subsection{ORA Multiplier-Accumulators}
\label{sct:bist-ora}
% Discuss ORA design
% DC1 and DC2 MAC
% Discuss in-phase and out-of-phase accumulations
% Probably will need to briefly mention cordic
After generating the analog frequencies required to stimulate the DUT the output of the DUT is analyzed by the BIST ORA.  The ORA consists of two multiplier-accumulators, $DC_1$ and $DC_2$\cite{basessa}.  By multiplying the response of the DUT by the cosine wave output of $NCO_3$, $DC_1$ will accumulate the out-of-phase component of the DUT response at the frequency of interest, $\omega$.  Likewise by multiplying the response of the DUT by the sine wave output of $NCO_3$, $DC_2$ will accumulate the in-phase component of the DUT response at $\omega$.  The accumulator values of both $DC_1$ and $DC_2$ can be described in Equations \ref{eq:DC1} and \ref{eq:DC2}. In these equations $nT_{clk}$ represents the sampled output response of the DUT\cite{stroud-phase}.  
\begin{equation}
DC_1 = \sum_{n} f(nT_{clk})*cos(\omega nT_{clk})
\label{eq:DC1}
\end{equation}
\begin{equation}
DC_2 = \sum_{n} f(nT_{clk})*sin(\omega nT_{clk})
\label{eq:DC2}
\end{equation}
It has been shown in \cite{jie}\cite{stroud-phase} and others that these calculations are similar to an FFT.  Unlike the FFT the entire frequency domain is not computed simultaneously; instead,  only a single frequency is measured for each accumulation\cite{stroud-phase}.  When more than one frequency $\omega$ is of interest, each must be measured through successive accumulations (each accumulation at a single frequency will be referred to as a single measurement).  

The $DC_1$ and $DC_2$ results of a measurement can be used to obtain both the amplitude and phase of the signal at the measured frequency $\omega$.  The amplitude calculation is shown in Equation \ref{eq:magnitude} and the phase calculation is shown in Equation \ref{eq:phase}\cite{jie}.
\begin{equation}
  A(\omega) = \sqrt{DC_1^2+DC_2^2}
  \label{eq:magnitude}
\end{equation}
\begin{equation}
  \Delta_\phi(\omega) = \tan^{-1}\frac{DC_2}{DC_1}
  \label{eq:phase}
\end{equation}
To obtain these measurements a hardware method must be used to calculate arc-tangent function used in Equation \ref{eq:phase} and the square and square-root functions used in Equation \ref{eq:magnitude}.  These calculations are performed using the on-chip calculation circuitry and will be discussed in the next section.

Before discussing the calculation circuitry, it is important to understand how the amount of accumulation time required for a measurement is determined.  The accumulation time is exceptionally important to achieving an accurate measurement due to potential AC calculation errors which are accumulated\cite{jie}.  A large body of work was put into determining both the appropriate length of time to accumulate and a method for determining the length of time efficiently in hardware.  \cite{jie} and \cite{testtime} discuss in detail the complexity of stopping accumulation at the correct moment to reduce the error.  As it is only pertinent to this thesis due to its relation to fault simulation time, it will only be briefly discussed here.  More details can be found in \cite{jie}.

As mentioned, there is the potential for errors to occur in an SSA approach due to AC errors accumulating in the ORA\cite{jie}.  One method of minimizing or eliminating these AC errors requires that the BIST accumulate for a very long period of time (referred to as free-run accumulation).  Unfortunately the amount of time required for accumulation would be prohibitively high\cite{testtime}.  \cite{jie} discusses a method of reducing the required accumulation time while still retaining the accuracy of free-run accumulation.  This method requires that accumulation occur for an exact number of clock cycles, determined by the integer multiple period (IMP)\nomenclature{IMP}{Integer Multiple Period} of the frequency being measured.  Though there are many complications to determining the IMP in hardware, it will be discussed at a high-level so that the reader can understand how measurement time is affected.

As explained in \cite{testtime}, if accumulation is stopped at a multiple of the interested frequency's period ($n*\frac{1}{f}$) the AC error will be greatly reduced resulting in a very accurate measurement.  This does not mean that frequencies with the shortest periods result in the shortest tests; instead, it is a function of both the frequency word chosen and the width of the phase accumulator which determines the length of the test.  More specifically the length of the test is determined by the effective number of bits used in the DDS by the frequency word ($M_{eff}$).  Equation \ref{eq:EffectiveBits} shows how the effective number of bits is calculated, where $M_{full}$ is the bit-width of the phase accumulator and $m$ is the bit position of the least significant `1` in the frequency word used\cite{jie}.  The resulting number of accumulation clock cycles is determined by $2^{M_eff}$.
\begin{equation}
	M_{eff} = M_{full} - m
	\label{eq:EffectiveBits}
\end{equation}
For example, if given a four-bit wide phase accumulator and the frequency word 1010 (or decimal 10), $M_{eff}$ would be equal to $4 - 1$ or 3.  This makes the required number of clock cycles $2^3$ or $8$.  In hardware this corresponds to the moment when all bits of the phase accumulator are logic `0' and the carry-out bit is a logic `1'\cite{jie}.  For large phase accumulators the number of clock cycles to accumulate can vary greatly depending on the frequency word chosen.  In the studied BIST, 16-bit phase accumulators are used.  In this case the difference between the shortest accumulation time of 2 clock cycles and than the longest accumulation time of 65535 clock cycles is significant.  Consequently frequency words should be carefully choosen so as to minimize test time\cite{jie}.  

The previous example represents the simple case where only a single tone is of interest.  For a multi-tone test (one where either two-tones are generated or where the measured tone is not the same as the generated tone) the IMP must be the common IMP of all frequency words\cite{jie}.  In this case logically OR'ing all frequency words together then calculating the resulting $M_eff$ number of bits will result in the number of clock cycles required for accumulation\cite{jie}\cite{testtime}.

In hardware a similar method is used which directly calculates the number of clock cycles required for accumulation.  After first OR'ing all frequency words together, an or-chain is used to determine the number of clock cycles to accumulate.  Figure \ref{fig:or-chain} shows this or-chain.  As shown in the figure, if a logic `1' is in the LSB of any of the frequency words, it will result in the maximum number of clock cycles for the given phase accumulator width.  
\begin{figure}
	\begin{center}
		\includegraphics[scale=1.3]{images/or-chain}
	\end{center}
	\caption{The OR Chain Which Calculates the Number of Clock Cycles from the Logical OR of All Frequency Words}
	\label{fig:or-chain}
\end{figure}
Using the resulting clock cycle count, the BIST uses a clock cycle counter to determine when to stop accumulation on an IMP and minimize the error.  Once accumulation has completed the calculation step is triggered and the results are handed off to the calculation circuitry for further processing.

\subsection{On-Chip Calculation Circuit}
\label{sct:onchip}
% Discuss importance of on-chip and how it differs from ORA
% Discuss calculation cordic
% Heavily reference original calculation circuit
% Discuss LOG circuit in joeys thesis verse new circuit which performs all calculations in log
% Discuss how calculations are performed at high-level (so without describing circuitry) for each test and which tests are available
% Linearity, Frequency Response, Spur Search, SNR, NF
The ORA portion of the BIST accumulates the in-phase and out-of-phase components into $DC_1$ and $DC_2$ at the frequency of interest.  Using these values more advanced measurements of special analog characteristics such as linearity, SNR, and NF can be performed.  To do this, $DC_1$ and $DC_2$ must be transformed mathematically into the relative magnitude and phase using Equations \ref{eq:magnitude} and \ref{eq:phase}\cite{joey}.  Traditionally this can be performed off-chip using a mathematical tool such as MATLAB; however, the BIST architecture discussed in this thesis uses an on-chip calculation circuit to perform both of these calculations and to perform multi-measurement tests on-chip\cite{joey}.  First the calculation cordic, which converts the $DC_1$ and $DC_2$ values to the magnitude and phase values, will be discussed.

\cite{joey} discusses the original implementation of the calculation circuitry for the BIST approach.  Shown in Figure \ref{fig:joeycalc} the original calculation circuit uses a custom CORDIC developed by \cite{joey} to perform the operations from Equations \ref{eq:magnitude} and \ref{eq:phase} and determine the magnitude and phase from the $DC_1$ and $DC_2$ values.
\begin{figure}
	\begin{center}
		\includegraphics[scale=1]{images/joey-calculation}
	\end{center}
	\caption{Calculation Circuit presented in \cite{joey}}
	\label{fig:joeycalc}
\end{figure}
The CORDIC algorithm, explained in depth in \cite{joey}, is a well-known, low-overhead approach to approximating a number of linear, circular, and hyperbolic functions using successive approximation and inexpensive digital operations such as shift, add, and substract.  Due to its low area-overhead and convience, an implementation of this algorithm is used to calculate the magnitude and phase from the $DC_1$ and $DC_2$ values\cite{joey}.  Since it requires successive approximation, the calculation cordic requires several clock cycles to complete.  At the end of the approximation the output of the calculation CORDIC is the raw magnitude and phase values which can be read directly and used by the remaining calculation circuitry to perform higher-order analysis\cite{joey}.

The remaining circuitry in the BIST is used for performing multi-measurement tests including measurements of the DUT linearity, SNR, noise figure (NF)\nomenclature{NF}{Noise Figure}, and spur searches. Before discussing each test in detail, it is important to understand that the result of the calculation circuit will be a logrithmic value expressed in decibels.  Decibels (dB)\nomenclature{dB}{Decibel} are a common unit used to represent signal strength.  To simplify the evaluation of test output, the calculation circuitry converts the output to decibels as described in Equation \ref{eq:decibel}\cite{joey}.  This operation is performed by the Logrithmic Translation Unit (LTU)\nomenclature{LTU}{Logarithmic Translation Unit} shown at the output in Figure \ref{fig:joeycalc}.  
\begin{equation}
dB = 20 * log_{10}(INPUT)
\label{eq:decibel}
\end{equation}

With the help of the test controller the BIST can perform multi-measurement tests and consequently measure several different important analog characteristics. The first such test measures the linearity of the analog DUT.  The linearity of a system is usually measured by analysis of the third-order inter-modulation point (IP3)\nomenclature{IP3}{Third-Order Inter-Modulation Point} using a two-tone test\cite{stroud-automaticlinearity}.  When two tones $f_1$ and $f_2$ are generated and are used to stimulate the DUT, the resulting output frequency will consist of not only $f_1$ and $f_2$ but also the IP3 terms caused by the non-linearity of the DUT.  The output spectrum is shown in Figure \ref{fig:linearityspectrum}.  
\begin{figure}
  \begin{center}
    \includegraphics[scale=1]{images/linearity-spectrum}
  \end{center}
  \caption{Input Spectrum v. DUT Output Response for two-tone test}
  \label{fig:linearityspectrum}
\end{figure}
The linearity of a system is the difference in magnitude between the fundamental tone and the IP3 tone; this is often referred to as $\Delta P$\cite{stroud-automaticlinearity}.  When performed in the BIST this requires two measurements.  In both measurements, two frequencies are generated by the DDS $f_1$ and $f_2$.  In the first test the measured frequency is set to $f_2$ and the ORA will accumulate the magnitude and phase of the fundamental frequency $f_2$.  This result is stored in the calculation circuit while a second measurement is performed.  The second measurement measures the IP3 tone at $2*f_2-f_1$\cite{testtime}\cite{jie}.  The resulting magnitude is subtracted from the magnitude of the previous calculation and the result is the $\Delta P$ or linearity of the system.

The spur search test searches a given spectrum for the largest magnitude frequency.  Spurious tones can appear in the spectrum and may negatively affect the output of a DUT.  These tones may be caused by undesired harmonics or due to other issues such as clipping.  It is often required to minimize spurious output and therefore it may be beneficial to measure the magnitude and location of spurious tones in the output of the DUT\cite{joey}.  To perform a spur search a fundamental frequency is generated by the DDS and a starting frequency $f_s$ is the first frequency in the bandwidth of interest.  To begin the test the frequency of interest $f$ is set to $f_s$ and the magnitude measured.  This magnitude is stored in the calculation circuitry while $f$ is incremented by a predetermined amount $f_{inc}$.  A new measurement will be made at the new frequency of interest $f$ and the magnitude compared to the previously recorded magnitude.  If the new magnitude is greater than the previously stored magnitude, the existing stored values are replaced with the new frequency word and magnitude.  This process will repeat for the number of samples specified.  The result of the test will be the magnitude and frequency word of the largest magnitude spur located in the measured bandwidth\cite{joey}.  In a special case, if $Samples = 0$ only a single frequency's magnitude is measured.  This allows for the frequency response of the DUT to be measured at the specified frequency.  This test can be repeated accross the spectrum to measure the frequency response of the DUT over the specified bandwidth\cite{stroud-automaticlinearity}.

Signal-to-Noise ratio (SNR) and noise figure (NF) are important characteristics of an analog system.  SNR measures the power of the signal of interest in comparison to the average power of the noise in the system over a specified bandwidth.  NF measures the amount of noise and signal degradation added to the system by the DUT by measuring the SNR at the input to the DUT $SNR_{in}$ and comparing it to the SNR at the output of the DUT $SNR_{out}$.  The formulas for these calculations are shown in Equations \ref{eq:snr} and \ref{eq:nf} respectively\cite{stroud-nf}.
\begin{equation}
SNR = \frac{Signal\ Power}{Average\ Noise\ Power}
\label{eq:snr}
\end{equation}
\begin{equation}
NF = \frac{SNR_{in}}{SNR_{out}}
\label{eq:nf}
\end{equation}
The BIST can directly perform these tests and measure both of these characteristics.  When performing a SNR measurement the BIST first measures the magnitude of the fundamental signal and stores it.  The next measurement begins at the starting frequency of the bandwidth of interest, $f$ and measures the magnitude.  This measurement is repeated for a predetermined number of samples and the result of each measurement is accumulated in the calculation circuit.  For each repetition the measured frequency $f$ is incremented by a constant $f_{inc}$ specified by the user.  After the specified number of samples have been taken, the accumulated noise power is divided by the number of samples to obtain an average noise power as shown in Equation \ref{eq:noisepower}, where $f_s$ is the starting frequency, $Samples$ is the number of noise samples to take, and $f_{inc}$ is the constant frequency value by which $f$ is incremented.
\begin{equation}
Average\ Noise\ Power =  \frac{\sum_{f=f_s}^{f_s+Samples*f_{inc}} |f|}{Samples}
\label{eq:noisepower}
\end{equation}
After the average noise power is calculated the original signal magnitude is divided by the noise power to obtain the SNR ratio shown in Equation \ref{eq:snr}.  The calculation for NF is very similar.  When performing a NF test the $SNR_{in}$ is calculated by bypassing the DUT (using the previously discussed bypass path) and then divided by the result of a second SNR test $SNR_{out}$ calculated using the standard loopback path.  The result is the NF ratio of the DUT\cite{stroud-nf}.

While the general principals and methods employed by the calculation circuit described in \cite{joey} are still used, improvements to this circuit have been made in the BIST studied in this thesis.  Like the previous calculation circuit it uses the same calculation CORDIC based on the design by \cite{joey} to convert the $DC_1$ and $DC_2$ values to their magnitude and phase representations.  Unlike the previous circuit, the LTU has been moved to the front of the circuit so that all operations are performed in the logarithmic domain.  The divider can then be replaced by a subtractor as division is performed via subtraction in the log domain.  Coupled with other improvements, the new circuit allows for faster operation and a large reduction in area and power (approximately 33\%).

\subsection{Summary}
% Communication mechanism for BIST
% High-level overview of the SPI
% Summarize the tests possible etc.
With an understanding of the TPG, ORA, and calculation circuitry of the BIST, the last important aspect of the BIST is how it is controlled and observed (recall that Section \ref{sct:whytest} states that controllability and observability directly influence the testability of a circuit).  Excluding a run signal and the ADC inputs, the majority of the BIST is controlled via a SPI interface.  A quick overview of this SPI interface is important to understanding the BIST model.  The SPI input to the BIST consists of an 88-bit SPI word which includes four 15-bit frequency words $FW_1$ through $FW_4$, the number of samples, and a test control word (TCW)\nomenclature{TCW}{Test Control Word} specifying which test to run.  $FW_1$ and $FW_2$ always control the two frequencies generated by the BIST DDS circuitry.  $FW_3$ and $FW_4$ have different meanings depending on the test run and are shown in Table \ref{tbl:fw34}.  
\begin{table}
  \caption{FW3 and FW4 Meanings}
  \begin{center}
    \begin{tabular}{|l|l|l|}
      \hline
      Test Type & Frequency Word 3 ($FW_3$) & Frequency Word 4 ($FW_4$) \\ \hline
      Linearity & Frequency of interest & Unused \\ \hline
      Spur Search & Starting Frequency $F_s$ & Increment Constant $F_{inc}$ \\ \hline
      SNR \& NF & Starting Frequency $F_s$ & Increment Constant $F_{inc}$ \\ \hline
    \end{tabular}
  \end{center}
  \label{tbl:fw34}
\end{table}
The number of samples is optional and will only be used if a spur search, SNR, or NF test is being executed as discussed in Section \ref{sct:onchip}.  The TCW includes the test type to run as well as some additional flags including those which optionally select  for the use of the digital loopback or bypass path and a bit to enable the use of the half-imp accumulation time\footnote{Half-IMP accumulation time causes the BIST to accumulate for half of the number of clock cycles that a test would usually require.  This introduces additional error into the calculation but will greatly decrease test-time for long tests.  This mode is used extensively for fault simulations.}.  

To read data out of the BIST the same SPI is used.  For a read to occur, a SPI write is performed with the read flag set and must include two address bits.  The address bits are decoded by the test controller and correspond to four different 64-bit words which can be read out of the BIST each containing different calculation data related to the test.  The values retrievable are shown in Table \ref{tbl:readvals}.  $DC_1$ and $DC_2$ correspond to the in-phase and out-of-phase components of the measured frequency.  The magnitude and phase output is the output of the calculation cordic and corresponds to the magnitude and phase of the measured signal (directly calculated from $DC_1$ and $DC_2$).  The final values include values specific to each test.  The ``Spur FW'' value corresponds to the location of a spur detected when performing a spur search, the ``Log Result'' represents the result of the test in dB, and finally the ``Noise Floor Value'' represents the average noise power as calculated during a SNR test.
\begin{table}
	\caption{Read Address Values}
	\begin{center}
		\begin{tabular}{|l|l|}
			\hline
			Address & Values \\ \hline
			00 & $DC_1$ \\ \hline
			01 & $DC_2$ \\ \hline
			10 & Magnitude and Phase \\ \hline
			11 & Spur FW, Log Result, Noise Floor Value \\ \hline			
		\end{tabular}
	\end{center}
	\label{tbl:readvals}
\end{table}

In addition to the SPI IO, there are a few other important outputs used in simulation.  First there is the DDS output which is the generated tone for the test being executed, there is also a 10-bit test result output which is the result of the test in dB.  Finally, there is a ``Done'' flag used to denote that the BIST has finished performing the test requested and that the results are ready for retrieval via the SPI.

\section{Thesis Statement}
While these descriptions of the BIST architecture are not a comprehensive operating manual, they are provided to give a background of the circuit so that a basic understanding can be developed by the reader.  The focus of the next chapters will shift to the actual fault simulations using the techniques discussed in Section \ref{sct:faultsim} and away from the underlying architecture except where it relates to potential improvements in fault coverage and the coverage that is achieved.  The goal of the techniques and methods discussed next as well as the goal of this thesis is to prove the effectiveness and necessity of the digital loopback path for achieving a high-fault coverage when testing a mixed-signal built-in self-test approach by using the studied BIST approach both as a benchmark and for context.
 

\chapter{Model Conversion and Verification}
\subsection{Converting to ASL}
In many cases behavioral models are written in a high-level hardware description language such as VESIC Hardware Description Language (VHDL)\nomenclature{VHDL}{VESIC Hardware Description Language} or Verilog.  These languages allow a behavioral model to be developed of a circuit at a much higher level than ASL's gate-level description.  This means that for large, complex circuits (such as our BIST approach) design in VHDL or Verilog is preferred.  To aid in the simulation of larger circuits a tool was developed to convert a Verilog net-list to an ASL net-list.  This allows a user to write a high-level behavioral description of the circuit, synthesis it down to a Verilog net-list using one of many different CAD tools, then convert it to ASL for fault simulation using the VerilogParser tool.

As a simple example the ISCAS '85 C17 benchmark circuit (Figure \ref{fig:c17_netlist}) was used to demonstrate the conversion process and the differences between a Verilog net-list and an ASL net-list.  In Figure \ref{fig:c17_netlist} A the behavioral model of the C17 circuit has been synthesized into a post-layout net-list in Verilog.  In B the Verilog model has been converted to ASL.
\begin{figure}[t]
	\begin{flushleft}
		\includegraphics[scale=1]{images/c17-verilog-netlist}	
	\end{flushleft}
	\begin{flushleft}
		(A) Verilog Net-list
	\end{flushleft}
	\begin{flushleft}
		\includegraphics[scale=1]{images/c17-asl-netlist}
	\end{flushleft}
	\begin{flushleft}
		(B) ASL Net-list
	\end{flushleft}
	\caption{C17 Benchmark Circuit Net-list}
	\label{fig:c17_netlist}
\end{figure}
The most significant challenge converting from Verilog to ASL is the difference in the treatment of inputs and outputs of gates and circuits.  In \ref{fig:c17_netlist} A, line 7 the instantiation of the AO21 gate is seen.  The gate's inputs and outputs are not designated separately.  In addition the net names are attached to their respective gate IO names.  In contrast, in \ref{fig:c17_netlist} B, line 2\footnote{The AO21 gate is a custom sub-circuit previously declared} the same gate is instantiated in ASL.  ASL uses a syntax that declares the inputs and outputs to a gate by position and not by name.  For the translation to be successful, the inputs and outputs to the gates must be ordered correctly.  Various techniques including lookup tables must be used to build the ASL correctly.

The VerilogParser tool performs the translation to ASL.  It is written in Microsoft .NET C\# 3.5.  The language was chosen due to the author's familiarity with the language as well as the extensive standard library included in .NET which simplified the program considerably\cite{csharp}.  As a quick reference Figure \ref{fig:VerilogParserUse} demonstrates how to use the tool on a Verilog net-list.
\begin{figure}
	\begin{center}
		\includegraphics[scale=.9]{images/verilog-asl-command}
	\end{center}
	\caption{Using the Verilog to ASL tool to convert a circuit to ASL}
	\label{fig:VerilogParserUse}
\end{figure}
The tool works by scanning the Verilog file for module definitions and parses the modules into an intermediate representation of the circuit.  It then prompts the user to choose which module should be used as the top-level circuit before outputting the resulting ASL.  Some improvements can be made to the converter such as automatic top-level module detection as well as the ability to convert VHDL net-lists; however, these features were not implemented due to time constraints.  It is important to note that while the ASL generated will always be syntactically correct, the tool does not check for validity of the circuit.  It is assumed any necessary sub-circuits that are used in the net-list have already been created and verified in ASL.  For a more detailed analysis of the Verilog to ASL parser please refer to the Appendix \ref{apdx:VerilogToASL}.  

\subsection{Generating Test Vectors using Vecgen}
Vecgen is a program written to generate AUSIM vector files.  It uses a straight forward command language to build a vector file of any length.  It is written in Microsoft's .NET C\#\cite{csharp} language. Vecgen addresses the issue of large circuits by using a concept called frames.  

The first line of a Vecgen file must be the GENERATE command which tells the generator how many frames(vectors) to generate and the number of primary inputs of the circuit.  If all the user provides is the GENERATE command then Vecgen will create a vector file with the specified number of vectors, filled with all `0' characters as wide as the number of primary inputs in the circuit.  This is the idea behind Vecgen, the vector each time is the same as the vector before it unless changed by the user in a frame.  There are a number of commands which are available to manipulate the output using Vecgen (the full list is available in Appendix \ref{apdx:Vecgen}).  An example generation command file, which would create the vector file shown in Table \ref{tbl:half_adder_vector}, is given in Table \ref{tbl:Vecgen_example} showing the Vecgen format:
\begin{table}
	\label{tbl:Vecgen_example}
	\begin{center}
		\begin{tabular}{l}
			GENERATE 4 2 \\		
			\\
			FRAME 1	\\
			BIT 0 1	\\
			\\
			FRAME 2	\\
			BIT 0 0	\\
			BIT 1 1	\\
			\\
			FRAME 3	\\
			BIT 0 1	\\
		\end{tabular}
	\end{center}
	\caption{Command to generate the half-adder vector sequence}
\end{table}
In the case of the half-adder example, the generator is much more verbose and would not be preferred; however, for this example one can see how it would help in more complex generation.  In our example FRAME 0 is not modified since the first vector generated is always all logic 0's.  FRAME 1 changes bit 0 to a logic 1 so that the resulting vector is now \textit{01}.  FRAME 2 changes bit 0 back to a logic 0 and changes bit 1 to a logic 1, resulting in \textit{10}.  Finally FRAME 3 updates bit 0 back to a logic 1 to obtain the vector \textit{11}.  Only at the times the output vector is changing does a FRAME need to be declared: if we were to generate ten frames instead of the four specified in the example, then the remaining six vectors would be automatically filled in and be the same \textit{11} vector set by FRAME 3.

This is a very simple example, there are many more commands as shown in Appendix \ref{apdx:Vecgen} that allow for much more powerful generation.  Some commands such as RANGE affect multiple bits at once, others such as SERIALIZE or CLOCK work over multiple frames.  One interesting command is the DECLARE command.  The DECLARE command creates a reusable group of commands which can be called from any frame.  This is especially useful if a certain sequence is required repeatedly during a test.  An example sequence and its output are shown in Table \ref{tbl:countsequence}.  The sequence creates a clock on its MSB, then calls a function which counts up then counts back down.  It then disables the clock and calls the counter function again.
\begin{table}
	\caption{Vecgen Example}
	\begin{center}
		\begin{tabular}{l|r|r}
		Commands & 1-15 & 16-24 \\ \hline
		GENERATE 24 3 & 100 & 001 \\
		 & 000 & 000 \\
		\textbf{DECLARE} counter & 101 & 000 \\
		FRAME 0	& 001 & 001 \\
		COUNT 0 2 U & 110 & 001 \\
		FRAME 8 & 010 & 010 \\
		COUNT 0 2 D & 111 & 010 \\
		\textbf{ENDDECLARE} & 011 & 011 \\ 
		 & 100 & 011 \\
 		\textbf{FRAME 0} & 000 & \\
		CLOCK 2 & 111 &  \\
		CALL counter & 011 & \\
		\textbf{FRAME 16} & 110 & \\
		BIT 2 0 & 010 &  \\
		CALL counter & 101 & \\
		\end{tabular}
	\end{center}
	\label{tbl:countsequence}
\end{table}
The generation in Table \ref{tbl:countsequence} is much more powerful than the previous example in Table \ref{tbl:Vecgen_example} and demonstrates some of the power that the Vecgen program provides.  All fault simulation tests for the BIST are designed in the Vecgen markup language for simplicity.
\chapter{Fault Simulations}

\chapter{Simulation Results}

\chapter{BIST Improvements}

\chapter{Conclusions and Summary}

% Bibliography
\begin{thebibliography}{99}
\bibitem{stroud} C. Stroud, \textit{A Designer's Guide to Built-In Self-Test}. Kluwer Academic Publishers, 2002.

\bibitem{itrs} \textit{The International Technology Roadmap for Semiconductors: 2009 Edition - Test \& Test Equipment}, Semiconductor Industry Association, San Jose, CA.

\bibitem{zorian} Y. Zorian, ``Testing the Monster Chip,'' \textit{IEEE Spectrum}, vol. 37, no. 7, pp. 54-60, 1999.

\bibitem{ungar} L. Ungar and T. Ambler, ``Economics of Built-In Self-Test,'' Proc. \textit{IEEE Design \& Test of Computers}, vol. 18, no. 5, pp. 70-79, 2001. 

\bibitem{syschip} L. Wang, C. Stroud, N. Touba, Eds., \textit{System On Chip Test Architectures}. Elsevier, 2008.

\bibitem{milor} L. Milor and V. Visvanathan, ``Detection of Catastrophic Faults in Analog Integrated Circuits,'' Proc. \textit{IEEE Transactions on Computered-Aided Design of Integrated Circuits and Systems}, vol. 8, no. 2, pp. 114-130, 1989.

\bibitem{stroud-analog} C. Stroud, P. Karunaratna, and E. Bardley, ``Digital Components for Built-In Self-Test of Analog Circuits,'' Proc. \textit{IEEE 10th ASIC Conference and Exhibit}, pp. 47-51, 1997.

\bibitem{ausim} C. Stroud, ``AUSIM: Auburn University SIMulator - version 2.0,'' Dept. of Electrical \& 
Computer Engineering, Auburn University, July 7, 2003.

\bibitem{asl} C. Stroud, ``ASL: Auburn Simulation Language,'' Dept. of Electrical \& Computer
Engineering, Auburn University, July 7, 2003.

\bibitem{verilog} ``IEEE Standard Hardware Description Language Based on the Verilog(R) Hardware Description Language,'' IEEE Std 1364-1995, 1996.

\bibitem{analogfaults} L. Milor, V. Visvanathan, ``Detection of Catastrophic Faults in Analog Integrated Circuits,'' \textit{IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems}, vol.8, no.2, pp.114-130, 1989.

\bibitem{analogosc} K. Arabi and B. Kaminska, ``Oscillation-Test Strategy for Analog and Mixed-Signal Integrated Circuits,'' Proc. \test{IEEE VLSI Test Symposium},  1996, pp. 476-482.

\bibitem{faultdiagnosis} V. Yarmolik, \textit{Fault Diagnosis of Digital Circuits}. John Wiley & Sons, 1990.

\bibitem{analogmixedtest} B. Vinnakota, \textit{Analog and Mixed-Signal Test}. Prentice Hall, 1998.

\bibitem{defectforcmos} M. Sachdev, \textit{Defect Oriented Testing for CMOS Analog and Digital Circuits}.  Kluwer Academic Pub, 1998.

\bibitem{stroud-bridging-physical} C. Stroud, J.Emmert, J. Bailey, D. Nickolic and K Chhor, ``Bridging Fault Extraction from Physical Design Data for Manufacturing Test Development'', Proc. \textit{IEEE International Test Conference}, 2000.

\bibitem{stroud-bridging} J.M. Emmert, C. Stroud, J.R. Bailey, ``A New Bridging Fault Model For Accurate Fault Behavior,'' Proc. \textit{IEEE Automatic Test Conference}, pp 481-485, 2000.

\bibitem{parallelflts} D.G. Saab, I.N. Hajj, J.T. Rahmeh, ``Parallel-Concurrent Fault Simulation,'' Proc. \textit{IEEE International Conference on Computer Design: VLSI in Computers and Processors}, pp.298-301, 1989.

\bibitem{advancedverilog} C. Last, \textit{Advanced Digital Design The Verilog HDL}.  Prentice-Hall, 2004.

\bibitem{testtime} J. Qin, C. Stroud, F. Dai, ``Test Time of Multiplier/Accumulator Based Output Response Analyzer in Built-In Analog Functional Testing,'' Proc. \textit{41st Southeastern Symposium on System Theory}, pp.363-367, 15-17 2009.

\bibitem{noisefigure} J. Qin, C. Stroud, F. Dai, ``Noise Figure Measurement Using Mixed-Signal BIST,'' Proc. \textit{IEEE International Symposium on Circuits and Systems}, pp.2180-2183, 27-30 2007.

\bibitem{basessa} F. Dai, C. Stroud, and D. Yang, ``Automatic Linearity and Frequency Response Tests with Built-in Pattern Generator and Analyzer,''  \textit{IEEE Transactions on VLSI Systems}, vol. 14, no. 6, pp. 561-572, 2006.

\bibitem{csharp} Microsoft. The C\# Language. Visual C\# Developer Center. [Online] \url{http://msdn.microsoft.com/en-us/vcsharp/aa336809.aspx}.

\bibitem{jie} J. Qin, ``Selective Spectrum Analysis (SSA) and Numerically Controlled Oscillator (NCO) in Mixed-Signal Built-In Self-Test,'' Doctoral Dissertation, Auburn University, 2010.

\bibitem{joey} G. Starr, ``Built-in Self-Test for the Analysis of Mixed-Signal Systems,'' Master's Thesis, Auburn University, 2010.

\bibitem{jie-journal} J. Qin, J. Cali, B. Dutton, G. Starr, F. Dai, C. Stroud, ``Selective Spectrum Analysis for Analog Measurements,'' \textit{IEEE Transactions on Industrial Electronics}, no.99, pp.1, 2011.

\bibitem{stroud-phase} J. Qin, C. Stroud, and F. Dai, ``Phase Delay Measurement and Calibration in Built-In Analog Functional Testing, Proc. \textit{IEEE Southeastern Symposium on System Theory}, pp. 145149, 2007.

\bibitem{qi} S. Qi, ``Analog Circuit Testing using Built-In Direct-Digital Synthesis,'' Master's Thesis, Auburn University, 2005.

\bibitem{stroud-automaticlinearity} F. Dai, C. Stroud, Y. Dayu, ``Automatic linearity and frequency response tests with built-in pattern generator and analyzer,'' Proc. \textit{IEEE Transactions on Very Large Scale Integration (VLSI) Systems} vol.14, no.6, pp.561-572, 2006.

\bibitem{stroud-nf} J. Qin, C. Stroud, F. Dai, ``Noise Figure Measurement Using Mixed-Signal BIST,'' Proc. \textit{IEEE International Symposium on Circuits and Systems}, pp.2180-2183, 2007.

\label{Bibliography}
\end{thebibliography}

\appendix
\addcontentsline{toc}{chapter}{Appendices}

\end{document}

